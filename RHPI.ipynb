{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c8892d",
   "metadata": {},
   "source": [
    "### RHPI analysis project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02736d11",
   "metadata": {},
   "source": [
    "## HPI data\n",
    "\n",
    "We start by loading the HPI data and the LAD to Region lookup table and joining the appropriate regions onto our HPI table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7983a78f-dc5b-4578-bb08-ef1a242d59e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                       object\n",
      "RegionName                 object\n",
      "AreaCode                   object\n",
      "AveragePrice                int64\n",
      "Index                     float64\n",
      "IndexSA                   float64\n",
      "1m%Change                 float64\n",
      "12m%Change                float64\n",
      "AveragePriceSA            float64\n",
      "SalesVolume               float64\n",
      "DetachedPrice             float64\n",
      "DetachedIndex             float64\n",
      "Detached1m%Change         float64\n",
      "Detached12m%Change        float64\n",
      "SemiDetachedPrice         float64\n",
      "SemiDetachedIndex         float64\n",
      "SemiDetached1m%Change     float64\n",
      "SemiDetached12m%Change    float64\n",
      "TerracedPrice             float64\n",
      "TerracedIndex             float64\n",
      "Terraced1m%Change         float64\n",
      "Terraced12m%Change        float64\n",
      "FlatPrice                 float64\n",
      "FlatIndex                 float64\n",
      "Flat1m%Change             float64\n",
      "Flat12m%Change            float64\n",
      "CashPrice                 float64\n",
      "CashIndex                 float64\n",
      "Cash1m%Change             float64\n",
      "Cash12m%Change            float64\n",
      "CashSalesVolume           float64\n",
      "MortgagePrice             float64\n",
      "MortgageIndex             float64\n",
      "Mortgage1m%Change         float64\n",
      "Mortgage12m%Change        float64\n",
      "MortgageSalesVolume       float64\n",
      "FTBPrice                  float64\n",
      "FTBIndex                  float64\n",
      "FTB1m%Change              float64\n",
      "FTB12m%Change             float64\n",
      "FOOPrice                  float64\n",
      "FOOIndex                  float64\n",
      "FOO1m%Change              float64\n",
      "FOO12m%Change             float64\n",
      "NewPrice                  float64\n",
      "NewIndex                  float64\n",
      "New1m%Change              float64\n",
      "New12m%Change             float64\n",
      "NewSalesVolume            float64\n",
      "OldPrice                  float64\n",
      "OldIndex                  float64\n",
      "Old1m%Change              float64\n",
      "Old12m%Change             float64\n",
      "OldSalesVolume            float64\n",
      "dtype: object\n",
      "Data successfully loaded to SQLite!\n",
      "Data successfully loaded to SQLite!\n",
      "   COUNT(DISTINCT RegionName)\n",
      "0                         405\n",
      "   COUNT(DISTINCT LAD23NM)\n",
      "0                      296\n",
      "   COUNT(DISTINCT RegionName)\n",
      "0                         295\n",
      "           LAD23NM    LAD23CD\n",
      "0  Isles of Scilly  E06000053\n"
     ]
    }
   ],
   "source": [
    "### import pandas as pd\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "#loading dataset\n",
    "df = pd.read_csv(\"UK-HPI-full-file-2025-03.csv\")\n",
    "\n",
    "#checking all data types\n",
    "print(df.dtypes)\n",
    "\n",
    "#connecting to SQLite database (creates new if nonexistent)\n",
    "conn = sqlite3.connect(\"house_prices_1.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#writing DataFrame to SQLite (replacing if table exists)\n",
    "try:\n",
    "    df.to_sql(name='uk_hpi', con=conn, if_exists='replace', index=False)\n",
    "    print(\"Data successfully loaded to SQLite!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "#updating 2 incorrect district codes (Barnsley,Sheffield) (see line 103)\n",
    "\n",
    "update = \"\"\" UPDATE uk_hpi\n",
    "SET AreaCode = CASE AreaCode\n",
    "    WHEN 'E08000038' THEN 'E08000016'\n",
    "    WHEN 'E08000039' THEN 'E08000019'\n",
    "    ELSE AreaCode \n",
    "END\n",
    "WHERE AreaCode IN ('E08000038', 'E08000039');\n",
    "\"\"\"\n",
    "cursor.execute(update)\n",
    "conn.commit()\n",
    "\n",
    "#loading LAD to Region lookup table\n",
    "#We will this to assign general regions (North West etc..) to regions in the HPI dataset\n",
    "\n",
    "df1 = pd.read_csv(\"Local_Authority_District_to_Region_(December_2023)_Lookup_in_England.csv\")\n",
    "\n",
    "try:\n",
    "    df1.to_sql(name='LAD_Regs', con=conn, if_exists='replace', index=False)\n",
    "    print(\"Data successfully loaded to SQLite!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "query1 = \"\"\"\n",
    "SELECT COUNT(DISTINCT RegionName)\n",
    "FROM uk_hpi \"\"\"\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT COUNT(DISTINCT LAD23NM)\n",
    "FROM LAD_Regs \"\"\"\n",
    "\n",
    "#comparing number of regions in datasets\n",
    "print(pd.read_sql_query(query1, conn))\n",
    "print(pd.read_sql_query(query2, conn))\n",
    "\n",
    "#disconnect between counts as LAD_reg only contains English regions\n",
    "\n",
    "#for this analysis we will only compare English regions so want to clear extras from HPI\n",
    "\n",
    "Joined_table = \"\"\" DROP TABLE IF EXISTS joined_tab;\n",
    "CREATE TABLE joined_tab AS\n",
    "SELECT uk_hpi.*, LAD_Regs.RGN23NM AS Standard_Region_Name\n",
    "FROM uk_hpi\n",
    "INNER JOIN LAD_Regs \n",
    "ON uk_hpi.AreaCode = LAD_Regs.LAD23CD;\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(Joined_table)\n",
    "\n",
    "check_join_0 = \"\"\"\n",
    "SELECT Date, RegionName, \"Index\"\n",
    "FROM joined_tab \"\"\"\n",
    "\n",
    "df4 = pd.read_sql_query(check_join_0, conn)\n",
    "df4.to_csv('HPI99.csv', index=False)\n",
    "\n",
    "#checking no of districts in new table\n",
    "query3 = \"\"\"\n",
    "SELECT COUNT(DISTINCT RegionName)\n",
    "FROM joined_tab\n",
    "\"\"\"\n",
    "\n",
    "#3 missing districts in joined_tabs, running SQL code to identify them\n",
    "query4 = \"\"\"\n",
    "SELECT\n",
    "    lku.LAD23NM,\n",
    "    lku.LAD23CD\n",
    "FROM\n",
    "    LAD_Regs AS lku\n",
    "LEFT JOIN\n",
    "    uk_hpi AS hpi\n",
    "ON\n",
    "    lku.LAD23CD = hpi.AreaCode\n",
    "WHERE\n",
    "    hpi.AreaCode IS NULL \"\"\"\n",
    "\n",
    "print(pd.read_sql_query(query3, conn))\n",
    "print(pd.read_sql_query(query4, conn))\n",
    "\n",
    "# identified 2 Districts with differing codes  between tables and 1 with no data(Isles of Scilly) so will make adjustment to this at start of code\n",
    "# in all cases LAD_Regs has correct code so will adjust UK_HPI (see line 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e425a",
   "metadata": {},
   "source": [
    "### HPI rebasing\n",
    "\n",
    "We have now added regions to the HPI data.\n",
    "\n",
    "Next step is to create 3 rebased HPI tables (bases = 2005,2015,2020). We need these to provide the option of ~ last 5/10/20 years in our interactive time series graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82a5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_2015 = \"\"\"\n",
    "DROP VIEW IF EXISTS uk_hpi_2015;\n",
    "CREATE VIEW uk_hpi_2015 AS\n",
    "SELECT\n",
    "    t1.Date,    \n",
    "    t1.RegionName AS District,\n",
    "    t1.Standard_Region_Name AS Region,\n",
    "    (t1.\"Index\" / base.\"Index\") * 100 AS \"Index\",\n",
    "    (t1.DetachedIndex / base.DetachedIndex) * 100 AS DetachedIndex,\n",
    "    (t1.SemiDetachedIndex / base.SemiDetachedIndex) * 100 AS SemiDetachedIndex,\n",
    "    (t1.TerracedIndex / base.TerracedIndex) * 100 AS TerracedIndex,\n",
    "    (t1.FlatIndex / base.FlatIndex) * 100 AS FlatIndex\n",
    "FROM joined_tab AS t1 \n",
    "JOIN uk_hpi AS base\n",
    "  ON t1.RegionName = base.RegionName\n",
    " AND base.Date = '2015-01-01';\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(view_2015)\n",
    "conn.commit()\n",
    "\n",
    "# Checking updated table\n",
    "check_2015 = \"\"\" SELECT *\n",
    "FROM uk_hpi_2015\n",
    "WHERE Date ='2015-08-01'\n",
    "LIMIT 5 \"\"\"\n",
    "\n",
    "#print(pd.read_sql_query(check_2015, conn))\n",
    "\n",
    "# I will now repeat this method to create a view with January 2020 base and a view with January 2006 base\n",
    "\n",
    "view_2020 = \"\"\"\n",
    "DROP VIEW IF EXISTS uk_hpi_2020;\n",
    "CREATE VIEW uk_hpi_2020 AS\n",
    "SELECT\n",
    "    t1.Date,    \n",
    "    t1.RegionName AS District,\n",
    "    t1.Standard_Region_Name AS Region,\n",
    "    (t1.\"Index\" / base.\"Index\") * 100 AS \"Index\",\n",
    "    (t1.DetachedIndex / base.DetachedIndex) * 100 AS DetachedIndex,\n",
    "    (t1.SemiDetachedIndex / base.SemiDetachedIndex) * 100 AS SemiDetachedIndex,\n",
    "    (t1.TerracedIndex / base.TerracedIndex) * 100 AS TerracedIndex,\n",
    "    (t1.FlatIndex / base.FlatIndex) * 100 AS FlatIndex\n",
    "FROM joined_tab AS t1 \n",
    "JOIN uk_hpi AS base\n",
    "  ON t1.RegionName = base.RegionName\n",
    " AND base.Date = '2020-01-01';\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(view_2020)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "view_2005 = \"\"\"\n",
    "DROP VIEW IF EXISTS uk_hpi_2005;\n",
    "CREATE VIEW uk_hpi_2005 AS\n",
    "SELECT\n",
    "    t1.Date,    \n",
    "    t1.RegionName AS District,\n",
    "    t1.Standard_Region_Name AS Region,\n",
    "    (t1.\"Index\" / base.\"Index\") * 100 AS \"Index\",\n",
    "    (t1.DetachedIndex / base.DetachedIndex) * 100 AS DetachedIndex,\n",
    "    (t1.SemiDetachedIndex / base.SemiDetachedIndex) * 100 AS SemiDetachedIndex,\n",
    "    (t1.TerracedIndex / base.TerracedIndex) * 100 AS TerracedIndex,\n",
    "    (t1.FlatIndex / base.FlatIndex) * 100 AS FlatIndex\n",
    "FROM joined_tab AS t1 \n",
    "JOIN uk_hpi AS base\n",
    "  ON t1.RegionName = base.RegionName\n",
    " AND base.Date = '2005-01-01';\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(view_2005)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19ba8a",
   "metadata": {},
   "source": [
    "### CPIH rebasing\n",
    "\n",
    "Loading CPIH data and rebasing in very similar way to HPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b219d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded to SQLite!\n",
      "             A      B\n",
      "0   2004-01-01   77.0\n",
      "1   2004-02-01   77.2\n",
      "2   2004-03-01   77.3\n",
      "3   2004-04-01   77.6\n",
      "4   2004-05-01   77.9\n",
      "..         ...    ...\n",
      "252 2025-01-01  135.1\n",
      "253 2025-02-01  135.6\n",
      "254 2025-03-01  136.1\n",
      "255 2025-04-01  137.7\n",
      "256 2025-05-01  138.0\n",
      "\n",
      "[257 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#loading CPIH table\n",
    "#Used excel to change the form of date data to match HPI table, eg, Jan-04 to 01/01/04 and to rearrange table from pivot to match HPI data\n",
    "\n",
    "df2 = pd.read_excel(\"CPIH1.xlsx\",  engine=\"openpyxl\")\n",
    "\n",
    "try:\n",
    "    df2.to_sql(name='CPIH_2015', con=conn, if_exists='replace', index=False)\n",
    "    print(\"Data successfully loaded to SQLite!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "print(df2)\n",
    "\n",
    "\n",
    "#In order to calculate RHPI for our adjusted bases we must first produce CPIH tables with adjusted bases\n",
    "\n",
    "CPIH_2015_J = \"\"\"\n",
    "DROP VIEW IF EXISTS CPIH_2015_J;\n",
    "CREATE VIEW CPIH_2015_J AS\n",
    "SELECT STRFTIME('%Y-%m-%d',A) AS A, (B / 99.2) * 100 AS B\n",
    "FROM CPIH_2015\"\"\"\n",
    "\n",
    "cursor.executescript(CPIH_2015_J)\n",
    "conn.commit()\n",
    "\n",
    "check_1 = \"\"\" SELECT * FROM CPIH_2015_J \"\"\"\n",
    "#print(pd.read_sql_query(check_1, conn))\n",
    "\n",
    "\n",
    "CPIH_2020 = \"\"\"\n",
    "DROP VIEW IF EXISTS CPIH_2020;\n",
    "CREATE VIEW CPIH_2020 AS\n",
    "SELECT STRFTIME('%Y-%m-%d',A) AS A, (B / 108.3) * 100 AS B\n",
    "FROM CPIH_2015\"\"\" \n",
    "\n",
    "cursor.executescript(CPIH_2020)\n",
    "conn.commit()\n",
    "\n",
    "check_2 = \"\"\" SELECT * FROM CPIH_2020 \"\"\"\n",
    "#print(pd.read_sql_query(check_2, conn))\n",
    "\n",
    "CPIH_2005 = \"\"\"\n",
    "DROP VIEW IF EXISTS CPIH_2005;\n",
    "CREATE VIEW CPIH_2005 AS\n",
    "SELECT STRFTIME('%Y-%m-%d',A) AS A, (B / 78.3) * 100 AS B\n",
    "FROM CPIH_2015\"\"\" \n",
    "\n",
    "cursor.executescript(CPIH_2005)\n",
    "conn.commit()\n",
    "\n",
    "check_3 = \"\"\" SELECT * FROM CPIH_2005 \"\"\"\n",
    "#print(pd.read_sql_query(check_3, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412bdc4",
   "metadata": {},
   "source": [
    "### Producing RHPI tables\n",
    "\n",
    "Using CPIH to adjust HPI for inflation for each base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8520921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date District                    Region        RHPI  \\\n",
      "0       2005-01-01     Adur                South East  100.000000   \n",
      "1       2005-02-01     Adur                South East   95.444094   \n",
      "2       2005-03-01     Adur                South East   96.508980   \n",
      "3       2005-04-01     Adur                South East   96.752739   \n",
      "4       2005-05-01     Adur                South East   98.412116   \n",
      "...            ...      ...                       ...         ...   \n",
      "126550  2024-11-01     York  Yorkshire and The Humber  100.254136   \n",
      "126551  2024-12-01     York  Yorkshire and The Humber   98.404080   \n",
      "126552  2025-01-01     York  Yorkshire and The Humber   97.516668   \n",
      "126553  2025-02-01     York  Yorkshire and The Humber   96.076478   \n",
      "126554  2025-03-01     York  Yorkshire and The Humber   97.191668   \n",
      "\n",
      "        RHPI_Detached  RHPI_Semi_Detached  RHPI_Terraced   RHPI_Flat BaseYear  \n",
      "0          100.000000          100.000000     100.000000  100.000000     2005  \n",
      "1           95.455106           95.687066      95.598266   95.438434     2005  \n",
      "2           96.373833           96.812194      96.756323   96.276400     2005  \n",
      "3           96.008319           97.080918      97.039174   96.595115     2005  \n",
      "4           97.766312           98.614610      98.830396   98.273972     2005  \n",
      "...               ...                 ...            ...         ...      ...  \n",
      "126550      99.783065          101.472000     102.157871   95.695772     2020  \n",
      "126551      97.636762           99.509073     100.178533   93.918596     2020  \n",
      "126552      96.748258           98.814593      99.477984   92.780189     2020  \n",
      "126553      95.112854           97.165239      98.213792   91.776457     2020  \n",
      "126554      95.351415           98.187031      99.442468   93.793547     2020  \n",
      "\n",
      "[126555 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#now we will generate RHPI table with 2006,2020 base\n",
    "\n",
    "RHPI_2015 = \"\"\" DROP TABLE IF EXISTS RHPI_2015;\n",
    "CREATE TABLE RHPI_2015 AS\n",
    "SELECT ab.Date, ab.District, ab.Region, (ab.\"Index\"/c.B ) * 100 AS RHPI, (ab.DetachedIndex/c.B) * 100 AS RHPI_Detached,\n",
    "(ab.SemiDetachedIndex/c.B) * 100 AS RHPI_Semi_Detached,(ab.TerracedIndex/c.B) * 100 AS RHPI_Terraced, (ab.FlatIndex/c.B) * 100 AS RHPI_Flat\n",
    "From uk_hpi_2015 AS ab\n",
    "LEFT JOIN CPIH_2015_J AS c\n",
    "ON ab.Date = STRFTIME('%Y-%m-%d', c.A) \n",
    "WHERE ab.Date > '2014-12-30'; \"\"\"\n",
    "\n",
    "cursor.executescript(RHPI_2015)\n",
    "conn.commit()\n",
    "\n",
    "check_join_1 = \"\"\"\n",
    "SELECT *\n",
    "FROM RHPI_2015\n",
    "\"\"\"\n",
    "\n",
    "RHPI_2020 = \"\"\" DROP TABLE IF EXISTS RHPI_2020;\n",
    "CREATE TABLE RHPI_2020 AS\n",
    "SELECT ab.Date, ab.District, ab.Region, (ab.\"Index\"/c.B ) * 100 AS RHPI, (ab.DetachedIndex/c.B) * 100 AS RHPI_Detached,\n",
    "(ab.SemiDetachedIndex/c.B) * 100 AS RHPI_Semi_Detached,(ab.TerracedIndex/c.B) * 100 AS RHPI_Terraced, (ab.FlatIndex/c.B) * 100 AS RHPI_Flat\n",
    "From uk_hpi_2020 AS ab\n",
    "LEFT JOIN CPIH_2020 AS c\n",
    "ON ab.Date = STRFTIME('%Y-%m-%d', c.A) \n",
    "WHERE ab.Date > '2019-12-30'; \"\"\"\n",
    "\n",
    "cursor.executescript(RHPI_2020)\n",
    "conn.commit()\n",
    "\n",
    "check_join_2 = \"\"\"\n",
    "SELECT *\n",
    "FROM RHPI_2020\n",
    "\"\"\"\n",
    "\n",
    "RHPI_2005 = \"\"\" DROP TABLE IF EXISTS RHPI_2005;\n",
    "CREATE TABLE RHPI_2005 AS\n",
    "SELECT ab.Date, ab.District, ab.Region, (ab.\"Index\"/c.B ) * 100 AS RHPI, (ab.DetachedIndex/c.B) * 100 AS RHPI_Detached,\n",
    "(ab.SemiDetachedIndex/c.B) * 100 AS RHPI_Semi_Detached,(ab.TerracedIndex/c.B) * 100 AS RHPI_Terraced, (ab.FlatIndex/c.B) * 100 AS RHPI_Flat\n",
    "From uk_hpi_2005 AS ab\n",
    "LEFT JOIN CPIH_2005 AS c\n",
    "ON ab.Date = STRFTIME('%Y-%m-%d', c.A) \n",
    "WHERE ab.Date > '2004-12-30'; \"\"\"\n",
    "\n",
    "cursor.executescript(RHPI_2005)\n",
    "conn.commit()\n",
    "\n",
    "check_join_3 = \"\"\"\n",
    "SELECT *\n",
    "FROM RHPI_2005\n",
    "\"\"\"\n",
    "\n",
    "# creating a unioned table of all 3 bases\n",
    "# This will allow us to easily visualize the RHPI data \n",
    "\n",
    "union = \"\"\" SELECT *,'2005' AS BaseYear               \n",
    "FROM RHPI_2005\n",
    "UNION ALL\n",
    "SELECT *,'2015' AS 'BaseYear'\n",
    "FROM RHPI_2015\n",
    "UNION ALL\n",
    "SELECT *, '2020' AS 'BaseYear'\n",
    "FROM RHPI_2020; \"\"\"\n",
    "\n",
    "print(pd.read_sql_query(union, conn))\n",
    "\n",
    "\n",
    "df6 = pd.read_sql_query(union, conn)\n",
    "df6.to_csv('/Users/bilallittle/Desktop/RHPI_union.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd11386",
   "metadata": {},
   "source": [
    "### BOE interest rates\n",
    "\n",
    "We are adding adjusted BOE interest rates to our visual time series as an option for a baseline.\n",
    "\n",
    "This will follow the same procces as RHPI (rebasing and adjusting)\n",
    "\n",
    "# 1) Loading and rebasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f529446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded to SQLite!\n",
      "    Date_Changed   Rate\n",
      "0     2025-05-08   4.25\n",
      "1     2025-02-06   4.50\n",
      "2     2024-11-07   4.75\n",
      "3     2024-08-01   5.00\n",
      "4     2023-08-03   5.25\n",
      "..           ...    ...\n",
      "251   1975-03-10  10.25\n",
      "252   1975-02-17  10.50\n",
      "253   1975-02-10  10.75\n",
      "254   1975-01-27  11.00\n",
      "255   1975-01-20  11.25\n",
      "\n",
      "[256 rows x 2 columns]\n",
      "           Date  Index_Value\n",
      "0    2005-01-01       100.00\n",
      "1    2005-02-01       100.39\n",
      "2    2005-03-01       100.78\n",
      "3    2005-04-01       101.17\n",
      "4    2005-05-01       101.56\n",
      "..          ...          ...\n",
      "238  2024-11-01       142.29\n",
      "239  2024-12-01       142.85\n",
      "240  2025-01-01       143.40\n",
      "241  2025-02-01       143.95\n",
      "242  2025-03-01       144.48\n",
      "\n",
      "[243 rows x 2 columns]\n",
      "           Date  Index_Value\n",
      "0    2015-01-01       100.00\n",
      "1    2015-02-01       100.04\n",
      "2    2015-03-01       100.08\n",
      "3    2015-04-01       100.12\n",
      "4    2015-05-01       100.17\n",
      "..          ...          ...\n",
      "118  2024-11-01       114.09\n",
      "119  2024-12-01       114.54\n",
      "120  2025-01-01       114.98\n",
      "121  2025-02-01       115.42\n",
      "122  2025-03-01       115.84\n",
      "\n",
      "[123 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#For my next step I want to use Bank of england interest rates to produce an Index which can be used as a comparison for the RHPI\n",
    "\n",
    "#downloading bank of england interest rate changes data\n",
    "df_6 = pd.read_csv(\"Bank Rate history and data  Bank of England Database.csv\")\n",
    "\n",
    "try:\n",
    "    df_6.to_sql(name='BOE_ir', con=conn, if_exists='replace', index=False)\n",
    "    print(\"Data successfully loaded to SQLite!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(pd.read_sql_query(\"\"\" SELECT * FROM BOE_ir \"\"\" ,conn))\n",
    "\n",
    "#creating a table with the current interest rate for the first of each month from interest rate change data\n",
    "\n",
    "cursor.execute(\"DROP INDEX IF EXISTS idx_boe_ir_date;\")\n",
    "cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_boe_ir_date ON BOE_ir(Date_Changed);\")\n",
    "conn.commit()\n",
    "\n",
    "rates = \"\"\" DROP TABLE IF EXISTS BOE_Interest_Rates;\n",
    "CREATE TABLE BOE_Interest_Rates AS\n",
    "WITH Months AS (SELECT Date from RHPI_2005) \n",
    "SELECT DISTINCT Months.Date,(\n",
    "        SELECT Rate\n",
    "        FROM BOE_ir\n",
    "        WHERE BOE_ir.Date_Changed <= Months.Date\n",
    "        ORDER BY BOE_ir.Date_Changed DESC\n",
    "        LIMIT 1\n",
    "    ) AS current_rate\n",
    "FROM\n",
    "     Months\n",
    "ORDER BY Months.Date; \"\"\"\n",
    "\n",
    "cursor.executescript(rates)\n",
    "conn.commit()\n",
    "\n",
    "rates_check = \"\"\"SELECT *\n",
    "FROM BOE_Interest_Rates\"\"\"\n",
    "\n",
    "#print(pd.read_sql_query(rates_check, conn))\n",
    "\n",
    "# Simple approach to create Savings_2005 table and rebased tables\n",
    "\n",
    "# Step 1: Create Savings_2005 table from query results\n",
    "savings_2005_query = \"\"\"\n",
    "WITH ordered_rates AS (\n",
    "    SELECT \n",
    "        Date,\n",
    "        current_rate,\n",
    "        POWER(1 + current_rate/100.0, 1.0/12.0) as monthly_factor,\n",
    "        ROW_NUMBER() OVER (ORDER BY Date) as row_num\n",
    "    FROM BOE_Interest_Rates\n",
    "    WHERE Date >= '2005-01-01'\n",
    "    ORDER BY Date\n",
    "),\n",
    "running_product AS (\n",
    "    SELECT \n",
    "        Date,\n",
    "        monthly_factor,\n",
    "        row_num,\n",
    "        100.0 as base_value\n",
    "    FROM ordered_rates\n",
    "    WHERE row_num = 1\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        o.Date,\n",
    "        o.monthly_factor,\n",
    "        o.row_num,\n",
    "        r.base_value * o.monthly_factor\n",
    "    FROM ordered_rates o\n",
    "    JOIN running_product r ON o.row_num = r.row_num + 1\n",
    ")\n",
    "SELECT Date, ROUND(base_value, 2) as Index_Value\n",
    "FROM running_product\n",
    "ORDER BY Date\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(savings_2005_query)\n",
    "conn.commit()\n",
    "print(pd.read_sql_query(savings_2005_query, conn))\n",
    "\n",
    "# Execute in Jupyter:\n",
    "df_savings_2005 = pd.read_sql_query(savings_2005_query, conn)\n",
    "df_savings_2005.to_sql('Savings_2005', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Step 2: Create rebased table for Jan 2015\n",
    "rebase_2015_query = \"\"\"DROP TABLE IF EXISTS Savings_2015_Rebased;\n",
    "CREATE TABLE Savings_2015_Rebased AS\n",
    "SELECT \n",
    "    Date,\n",
    "    ROUND((Index_Value / (SELECT Index_Value FROM Savings_2005 WHERE Date = '2015-01-01')) * 100, 2) as Index_Value\n",
    "FROM Savings_2005\n",
    "WHERE Date >= '2015-01-01'\n",
    "ORDER BY Date\n",
    "\"\"\"\n",
    "cursor.executescript(rebase_2015_query)\n",
    "conn.commit()\n",
    "print(pd.read_sql_query(\"\"\"SELECT * FROM Savings_2015_Rebased\"\"\", conn))\n",
    "\n",
    "# Step 3: Create rebased table for Jan 2020\n",
    "rebase_2020_query = \"\"\"DROP TABLE IF EXISTS Savings_2020_Rebased;\n",
    "CREATE TABLE Savings_2020_Rebased AS\n",
    "SELECT \n",
    "    Date,\n",
    "    ROUND((Index_Value / (SELECT Index_Value FROM Savings_2005 WHERE Date = '2020-01-01')) * 100, 2) as Index_Value\n",
    "FROM Savings_2005\n",
    "WHERE Date >= '2020-01-01'\n",
    "ORDER BY Date\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(rebase_2020_query)\n",
    "conn.commit()\n",
    "#print(pd.read_sql_query(\"\"\"SELECT * FROM Savings_2020_Rebased\"\"\", conn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3962e",
   "metadata": {},
   "source": [
    "# Adjusting BOE using CPIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b295db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Queries to adjust savings indexes for CPIH inflation data\n",
    "# Using matching CPIH base years: CPIH_2005 for Savings_2005, etc.\n",
    "\n",
    "# 1. CPIH-adjusted Savings Index (2005 base)\n",
    "\n",
    "Savings_2005 = \"\"\" DROP TABLE IF EXISTS Savings_2005_Real;\n",
    "CREATE TABLE Savings_2005_Real AS\n",
    "SELECT \n",
    "    s.Date,\n",
    "    ROUND((s.Index_Value / c.B) * 100, 2) as Real_Index_Value,\n",
    "    2005 AS BaseYear\n",
    "FROM Savings_2005 s\n",
    "JOIN CPIH_2005 c ON s.Date = c.A\n",
    "ORDER BY s.Date;\n",
    "\"\"\"\n",
    "cursor.executescript(Savings_2005)\n",
    "conn.commit()\n",
    "#print(pd.read_sql_query(\"\"\"SELECT * FROM Savings_2005_Real\"\"\", conn))\n",
    "\n",
    "# 2. CPIH-adjusted Savings Index (2015 base)\n",
    "Savings_2015_Real = \"\"\" DROP TABLE IF EXISTS Savings_2015_Real; \n",
    "CREATE TABLE Savings_2015_Real AS\n",
    "SELECT \n",
    "    s.Date,\n",
    "    ROUND((s.Index_Value / c.B) * 100, 2) as Real_Index_Value,\n",
    "    2015 AS BaseYear\n",
    "FROM Savings_2015_Rebased s\n",
    "JOIN CPIH_2015_J c ON s.Date = c.A\n",
    "ORDER BY s.Date;\"\"\"\n",
    "\n",
    "cursor.executescript(Savings_2015_Real)\n",
    "conn.commit()\n",
    "#print(pd.read_sql_query(\"\"\"SELECT * FROM Savings_2015_Real\"\"\", conn))\n",
    "\n",
    "# 3. CPIH-adjusted Savings Index (2020 base)\n",
    "Savings_2020_Real = \"\"\" DROP TABLE IF EXISTS Savings_2020_Real;\n",
    "CREATE TABLE Savings_2020_Real AS\n",
    "SELECT \n",
    "    s.Date,\n",
    "    ROUND((s.Index_Value / c.B) * 100, 2) as Real_Index_Value,\n",
    "    2020 AS BaseYear\n",
    "FROM Savings_2020_Rebased s\n",
    "JOIN CPIH_2020 c ON s.Date = c.A\n",
    "ORDER BY s.Date; \"\"\"\n",
    "\n",
    "cursor.executescript(Savings_2020_Real)\n",
    "conn.commit()\n",
    "#print(pd.read_sql_query(\"\"\"SELECT * FROM Savings_2020_Real\"\"\", conn))\n",
    "\n",
    "#We now have 3 Savings tables with CPIH adjustments for each base year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736af4c1",
   "metadata": {},
   "source": [
    "# snp500\n",
    "\n",
    "Following the same steps to produce adjusted snp500 as our final baseline\n",
    "\n",
    "### 1) Loading and rebasing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9efffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded to SQLite!\n",
      "Data successfully loaded to SQLite!\n",
      "          Date  ov_p_return  index_2020_base\n",
      "0   2020-01-01    -0.078512           100.00\n",
      "1   2020-02-01    -0.127872            87.21\n",
      "2   2020-03-01     0.132784            98.79\n",
      "3   2020-04-01     0.052607           103.99\n",
      "4   2020-05-01     0.021689           106.25\n",
      "..         ...          ...              ...\n",
      "61  2025-02-01    -0.058821           208.51\n",
      "62  2025-03-01    -0.008751           206.69\n",
      "63  2025-04-01     0.061345           219.37\n",
      "64  2025-05-01     0.051340           230.63\n",
      "65  2025-06-01          NaN           230.63\n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Now we will begin the process of producing snp500 indexes for each base year\n",
    "\n",
    "#downloading snp500 data\n",
    "df7 = pd.read_csv(\"snp500.csv\")\n",
    "\n",
    "try:\n",
    "    df7.to_sql(name='snp500_o', con=conn, if_exists='replace', index=False)\n",
    "    print(\"Data successfully loaded to SQLite!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "#downloading dividend data\n",
    "df8 = pd.read_csv(\"Dividends.csv\")\n",
    "\n",
    "try:\n",
    "    df8.to_sql(name='dividends', con=conn, if_exists='replace', index=False)\n",
    "    print(\"Data successfully loaded to SQLite!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "#joining snp500 and dividends tables \n",
    "#the calculation in the select is combining snp%change and dividend rate to get overall percentage change per month\n",
    "\n",
    "join_snp = \"\"\" DROP TABLE IF EXISTS snp500;\n",
    "CREATE TABLE snp500 AS\n",
    "SELECT o.Date, ((1 + o.snp_p_change) * (1 + (d.Dividend / (12 * o.Price * 1000))) - 1) AS ov_p_return\n",
    "FROM snp500_o AS o\n",
    "LEFT JOIN dividends AS d\n",
    "ON o.Date = d.Date \n",
    ";\"\"\"\n",
    "\n",
    "cursor.executescript(join_snp)\n",
    "conn.commit()\n",
    "#checking joined table\n",
    "#print(pd.read_sql_query(\"\"\" SELECT * FROM snp500; \"\"\", conn))\n",
    "\n",
    "\n",
    "#now we will calculate indexes for our 3 Base years\n",
    "snp500_2005 = \"\"\"WITH RECURSIVE index_calc_2005 AS (\n",
    "    -- Base case: January 2005 = 100\n",
    "    SELECT \n",
    "        Date,\n",
    "        ov_p_return,\n",
    "        100.0 as index_value\n",
    "    FROM snp500\n",
    "    WHERE Date = '2005-01-01'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- Recursive case: multiply previous index by (1 + monthly_return)\n",
    "    SELECT \n",
    "        s.Date,\n",
    "        s.ov_p_return,\n",
    "        i.index_value * (1 + COALESCE(s.ov_p_return, 0)) as index_value\n",
    "    FROM snp500 s\n",
    "    INNER JOIN index_calc_2005 i ON s.Date = (\n",
    "        SELECT MIN(s2.Date) \n",
    "        FROM snp500 s2 \n",
    "        WHERE s2.Date > i.Date AND s2.Date >= '2005-01-01'\n",
    "    )\n",
    "    WHERE s.Date >= '2005-01-01'\n",
    ")\n",
    "SELECT \n",
    "    Date,\n",
    "    ov_p_return,\n",
    "    ROUND(index_value, 2) as index_2005_base\n",
    "FROM index_calc_2005\n",
    "ORDER BY Date ; \"\"\"\n",
    "\n",
    "cursor.executescript(snp500_2005)\n",
    "conn.commit()\n",
    "\n",
    "df_snp_2005 = pd.read_sql_query(snp500_2005, conn)\n",
    "df_snp_2005.to_sql('snp500_2005', conn, if_exists='replace', index=False)\n",
    "\n",
    "#checking snp500_2005 table\n",
    "#print(pd.read_sql_query(\"\"\" SELECT * FROM snp500_2005; \"\"\", conn))\n",
    "\n",
    "\n",
    "#INDEX WITH BASE JANUARY 2015 (Base = 100)\n",
    "snp500_2015 = \"\"\"\n",
    "WITH RECURSIVE index_calc_2015 AS (\n",
    "    -- Base case: January 2015 = 100\n",
    "    SELECT \n",
    "        Date,\n",
    "        ov_p_return,\n",
    "        100.0 as index_value\n",
    "    FROM snp500\n",
    "    WHERE Date = '2015-01-01'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- Recursive case: multiply previous index by (1 + monthly_return)\n",
    "    SELECT \n",
    "        s.Date,\n",
    "        s.ov_p_return,\n",
    "        i.index_value * (1 + COALESCE(s.ov_p_return, 0)) as index_value\n",
    "    FROM snp500 s\n",
    "    INNER JOIN index_calc_2015 i ON s.Date = (\n",
    "        SELECT MIN(s2.Date) \n",
    "        FROM snp500 s2 \n",
    "        WHERE s2.Date > i.Date AND s2.Date >= '2015-01-01'\n",
    "    )\n",
    "    WHERE s.Date >= '2015-01-01'\n",
    ")\n",
    "SELECT \n",
    "    Date,\n",
    "    ov_p_return,\n",
    "    ROUND(index_value, 2) as index_2015_base\n",
    "FROM index_calc_2015\n",
    "ORDER BY Date; \"\"\"\n",
    "\n",
    "cursor.executescript(snp500_2015)\n",
    "conn.commit()\n",
    "\n",
    "df_snp_2015 = pd.read_sql_query(snp500_2015, conn)\n",
    "df_snp_2015.to_sql('snp500_2015', conn, if_exists='replace', index=False)\n",
    "\n",
    "#checking snp500_2015 table\n",
    "#print(pd.read_sql_query(\"\"\" SELECT * FROM snp500_2015; \"\"\", conn))\n",
    "\n",
    "#INDEX WITH BASE JANUARY 2020 (Base = 100)\n",
    "snp500_2020 = \"\"\"\n",
    "WITH RECURSIVE index_calc_2020 AS (\n",
    "    -- Base case: January 2020 = 100\n",
    "    SELECT \n",
    "        Date,\n",
    "        ov_p_return,\n",
    "        100.0 as index_value\n",
    "    FROM snp500\n",
    "    WHERE Date = '2020-01-01'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- Recursive case: multiply previous index by (1 + monthly_return)\n",
    "    SELECT \n",
    "        s.Date,\n",
    "        s.ov_p_return,\n",
    "        i.index_value * (1 + COALESCE(s.ov_p_return, 0)) as index_value\n",
    "    FROM snp500 s\n",
    "    INNER JOIN index_calc_2020 i ON s.Date = (\n",
    "        SELECT MIN(s2.Date) \n",
    "        FROM snp500 s2 \n",
    "        WHERE s2.Date > i.Date AND s2.Date >= '2020-01-01'\n",
    "    )\n",
    "    WHERE s.Date >= '2020-01-01'\n",
    ")\n",
    "SELECT \n",
    "    Date,\n",
    "    ov_p_return,\n",
    "    ROUND(index_value, 2) as index_2020_base\n",
    "FROM index_calc_2020\n",
    "ORDER BY Date; \"\"\"\n",
    "\n",
    "cursor.executescript(snp500_2020)\n",
    "conn.commit()\n",
    "df_snp_2020 = pd.read_sql_query(snp500_2020, conn)\n",
    "df_snp_2020.to_sql('snp500_2020', conn, if_exists='replace', index=False)\n",
    "\n",
    "#checking snp500_2020 table\n",
    "print(pd.read_sql_query(\"\"\" SELECT * FROM snp500_2020; \"\"\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be55f9",
   "metadata": {},
   "source": [
    "### Adjusting snp500 with CPIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06629090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  real_index_2005_base\n",
      "0    2005-01-01                100.00\n",
      "1    2005-02-01                 97.91\n",
      "2    2005-03-01                 95.75\n",
      "3    2005-04-01                 98.41\n",
      "4    2005-05-01                 98.21\n",
      "..          ...                   ...\n",
      "240  2025-01-01                449.96\n",
      "241  2025-02-01                421.92\n",
      "242  2025-03-01                416.70\n",
      "243  2025-04-01                437.12\n",
      "244  2025-05-01                458.56\n",
      "\n",
      "[245 rows x 2 columns]\n",
      "           Date  real_index_2015_base\n",
      "0    2015-01-01                100.00\n",
      "1    2015-02-01                 97.86\n",
      "2    2015-03-01                 98.91\n",
      "3    2015-04-01                 99.77\n",
      "4    2015-05-01                 97.74\n",
      "..          ...                   ...\n",
      "120  2025-01-01                258.93\n",
      "121  2025-02-01                242.80\n",
      "122  2025-03-01                239.79\n",
      "123  2025-04-01                251.54\n",
      "124  2025-05-01                263.89\n",
      "\n",
      "[125 rows x 2 columns]\n",
      "          Date  real_index_2020_base\n",
      "0   2020-01-01                100.00\n",
      "1   2020-02-01                 86.97\n",
      "2   2020-03-01                 98.52\n",
      "3   2020-04-01                103.70\n",
      "4   2020-05-01                105.96\n",
      "..         ...                   ...\n",
      "60  2025-01-01                177.60\n",
      "61  2025-02-01                166.53\n",
      "62  2025-03-01                164.47\n",
      "63  2025-04-01                172.53\n",
      "64  2025-05-01                180.99\n",
      "\n",
      "[65 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adjust S&P 500 2005 Index using CPIH_2005\n",
    "query_adjust_2005 = \"\"\"\n",
    "DROP TABLE IF EXISTS snp500_real_2005_base;\n",
    "CREATE TABLE snp500_real_2005_base AS\n",
    "SELECT \n",
    "    s.Date,\n",
    "    ROUND((s.index_2005_base / c.B) * 100, 2) as real_index_2005_base\n",
    "FROM snp500_2005 s\n",
    "LEFT JOIN CPIH_2005 c ON s.Date = c.A\n",
    "WHERE c.B IS NOT NULL\n",
    "ORDER BY s.Date;\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(query_adjust_2005)\n",
    "conn.commit()\n",
    "\n",
    "#Adjusting all snp tables for CPIH\n",
    "\n",
    "# Adjust S&P 500 2015 Index using CPIH_2015_J\n",
    "query_adjust_2015 = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS snp500_real_2015_base AS\n",
    "SELECT \n",
    "    s.Date,\n",
    "    ROUND((s.index_2015_base / c.B) * 100, 2) as real_index_2015_base\n",
    "FROM snp500_2015 s\n",
    "LEFT JOIN CPIH_2015_J c ON s.Date = c.A\n",
    "WHERE c.B IS NOT NULL\n",
    "ORDER BY s.Date;\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(query_adjust_2015)\n",
    "conn.commit()\n",
    "\n",
    "# Adjust S&P 500 2020 Index using CPIH_2020\n",
    "query_adjust_2020 = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS snp500_real_2020_base AS\n",
    "SELECT \n",
    "    s.Date,\n",
    "    ROUND((s.index_2020_base / c.B) * 100, 2) as real_index_2020_base\n",
    "FROM snp500_2020 s\n",
    "LEFT JOIN CPIH_2020 c ON s.Date = c.A\n",
    "WHERE c.B IS NOT NULL\n",
    "ORDER BY s.Date;\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(query_adjust_2020)\n",
    "conn.commit()\n",
    "\n",
    "print(pd.read_sql_query(\"\"\" SELECT * FROM snp500_real_2005_base; \"\"\", conn))\n",
    "print(pd.read_sql_query(\"\"\" SELECT * FROM snp500_real_2015_base; \"\"\", conn))\n",
    "print(pd.read_sql_query(\"\"\" SELECT * FROM snp500_real_2020_base; \"\"\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb186a78",
   "metadata": {},
   "source": [
    "# Unioned table\n",
    "\n",
    "Creating final unioned table for data vizualization in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fc6b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "union_1:\n",
      "                 name  type\n",
      "0                Date  TEXT\n",
      "1            District  TEXT\n",
      "2              Region  TEXT\n",
      "3                RHPI  REAL\n",
      "4       RHPI_Detached  REAL\n",
      "5  RHPI_Semi_Detached  REAL\n",
      "6       RHPI_Terraced  REAL\n",
      "7           RHPI_Flat  REAL\n",
      "8            BaseYear  TEXT\n",
      "\n",
      "Savings_2005_Real:\n",
      "               name  type\n",
      "0              Date  TEXT\n",
      "1  Real_Index_Value      \n",
      "2          BaseYear      \n",
      "\n",
      "Savings_2015_Real:\n",
      "               name  type\n",
      "0              Date  TEXT\n",
      "1  Real_Index_Value      \n",
      "2          BaseYear      \n",
      "\n",
      "Savings_2020_Real:\n",
      "               name  type\n",
      "0              Date  TEXT\n",
      "1  Real_Index_Value      \n",
      "2          BaseYear      \n",
      "\n",
      "snp500_real_2005_base:\n",
      "                   name  type\n",
      "0                  Date  TEXT\n",
      "1  real_index_2005_base      \n",
      "\n",
      "snp500_real_2015_base:\n",
      "                   name  type\n",
      "0                  Date  TEXT\n",
      "1  real_index_2015_base      \n",
      "\n",
      "snp500_real_2020_base:\n",
      "                   name  type\n",
      "0                  Date  TEXT\n",
      "1  real_index_2020_base      \n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"house_prices_1.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Storing RHPI union as sql table\n",
    "df_00 = pd.read_sql_query(union, conn)\n",
    "df_00.to_sql('union_1', conn, if_exists='replace', index=False)\n",
    "\n",
    "# finally creating a union of RHPI,Savings,snp data for vizualization\n",
    "\n",
    "# All tables have different columns/ different numbers of columns \n",
    "# so this makes creating a combined table slightly harder\n",
    "\n",
    "# Will start by viewing all columns in each table\n",
    "\n",
    "tables = ['union_1', 'Savings_2005_Real', 'Savings_2015_Real', \n",
    "         'Savings_2020_Real', 'snp500_real_2005_base', \n",
    "         'snp500_real_2015_base', 'snp500_real_2020_base']\n",
    "\n",
    "for table in tables:\n",
    "    print(f\"\\n{table}:\")\n",
    "    result = pd.read_sql(f\"PRAGMA table_info({table})\", conn)\n",
    "    print(result[['name', 'type']]) \n",
    "\n",
    "union_all = \"\"\"-- Drop existing table if it exists\n",
    "DROP TABLE IF EXISTS all_combined;\n",
    "\n",
    "-- Create the combined table with all columns\n",
    "CREATE TABLE all_combined (\n",
    "    Date TEXT,\n",
    "    District TEXT,\n",
    "    Region TEXT,\n",
    "    RHPI REAL,\n",
    "    RHPI_Detached REAL,\n",
    "    RHPI_Semi_Detached REAL,\n",
    "    RHPI_Terraced REAL,\n",
    "    RHPI_Flat REAL,\n",
    "    Real_Index_Value REAL,\n",
    "    real_index_2005_base REAL,\n",
    "    real_index_2015_base REAL,\n",
    "    real_index_2020_base REAL,\n",
    "    BaseYear TEXT,\n",
    "    source_table TEXT\n",
    ");\n",
    "\n",
    "-- Insert from each table\n",
    "INSERT INTO all_combined (Date, District, Region, RHPI, RHPI_Detached, RHPI_Semi_Detached, RHPI_Terraced, RHPI_Flat, BaseYear, source_table)\n",
    "SELECT Date, District, Region, RHPI, RHPI_Detached, RHPI_Semi_Detached, RHPI_Terraced, RHPI_Flat, BaseYear, 'union_1' FROM union_1;\n",
    "\n",
    "INSERT INTO all_combined (Date, Real_Index_Value, BaseYear, source_table)\n",
    "SELECT Date, Real_Index_Value, BaseYear, 'Savings_2005_Real' FROM Savings_2005_Real;\n",
    "\n",
    "INSERT INTO all_combined (Date, Real_Index_Value, BaseYear, source_table)\n",
    "SELECT Date, Real_Index_Value, BaseYear, 'Savings_2015_Real' FROM Savings_2015_Real;\n",
    "\n",
    "INSERT INTO all_combined (Date, Real_Index_Value, BaseYear, source_table)\n",
    "SELECT Date, Real_Index_Value, BaseYear, 'Savings_2020_Real' FROM Savings_2020_Real;\n",
    "\n",
    "INSERT INTO all_combined (Date, real_index_2005_base, source_table)\n",
    "SELECT Date, real_index_2005_base, 'snp500_real_2005_base' FROM snp500_real_2005_base;\n",
    "\n",
    "INSERT INTO all_combined (Date, real_index_2015_base, source_table)\n",
    "SELECT Date, real_index_2015_base, 'snp500_real_2015_base' FROM snp500_real_2015_base;\n",
    "\n",
    "INSERT INTO all_combined (Date, real_index_2020_base, source_table)\n",
    "SELECT Date, real_index_2020_base, 'snp500_real_2020_base' FROM snp500_real_2020_base;\n",
    "\"\"\"\n",
    "cursor.executescript(union_all)\n",
    "conn.commit()\n",
    "\n",
    "# Checking the combined table\n",
    "union_all_1 = \"\"\" SELECT * FROM all_combined; \"\"\"\n",
    "df_combined = pd.read_sql_query(union_all_1, conn)\n",
    "df_combined.to_csv('all_combined.csv', index=False)\n",
    "\n",
    "\n",
    "conn.close()\n",
    "print(\"\\nDatabase connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
